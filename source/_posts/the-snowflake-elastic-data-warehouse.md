> 原文：[The snowflake elastic data warehouse](https://dl.acm.org/doi/abs/10.1145/2882903.2903741)

## TL;DR

<!--more-->

## Introduction

云时代来临了，但传统的数仓方案还是在云时代之前的，只能跑在小型的、静态的、指定机器的集群上，而没办法真正利用云设施。

除了平台在改变，数据也在改变。过去数仓要处理的数据都来自相同组织内部，它们的结构、容量、产生速度都是可以预期和规划的。但云数仓的数据来自不容易控制的外部，而且经常是没有schema的半结构化数据。面对这些数据时，传统数仓力不从心，它们严重依赖ETL pipeline和根据已知的数据特点来手动调优。

后续产生的Hadoop、Spark、Stinger Initiative等方案仍然无法满足云时代对数仓的需求，尤其是它们都需要花费大量人力做运维和调优。

Snowflake与这些方案的区别在于它是真正利用云设施的经济、弹性、服务化等优点的数仓产品。它的关键特性如下：
- 纯正的SaaS体验。用户不需要关心机器、运维、调优、扩容，只要数据上传到Snowflake，立即就可以开始分析。
- 支持SQL和ACID的事务。
- 支持JSON和Avro之类的半结构化数据，可以遍历、摊平、嵌套，利益于自动的schema发现和列存格式，操作半结构化数据的效率与结构化数据一样高。
- 弹性的存储与计算资源。
- 高可用。
- 数据可靠性。
- 费用合理，用户只需要为存储（压缩后）和使用的计算资源付费。
- 安全性，所有数据和网络都是端到端加密的，用户还可以基于role来做细粒度访问控制（SQL级别）。

这篇文章中Snowflake使用的是AWS的资源，目前它也已经支持了Azure和GCP。

## Storage Versus Compute

shared-nothing架构在高性能数仓领域占据了主导地位，它的优点是规模与硬件便宜。这种设计很适合星型query，在join一个小的维表（broadcast）和一个大的事实表（partition）时只需要很小的带宽。

但这种shard-nothing架构有个严重缺陷：计算与存储耦合。以下场景会有问题：
- 异构负载。一种系统配置很难同时满足批量导入（高I/O带宽，低运算）和复杂query处理（低I/O带宽，高运算），最终可能两种都不高效。
- 扩缩容时会有大量数据需要搬迁，过程中现存节点也会受影响。
- 在线升级。想要完全不影响服务，理论上可以，但实际很难，尤其是各种资源耦合在一起，又有着同质化假设时。

云环境下这些场景都会出现。

因此Snowflake选择了计算存储分离的架构，其中计算使用了AWS EC2，存储则使用AWS S3。每台机器上还会在本地盘上缓存数据。如果cache是热的，这种架构的性能可以达到甚至超过shared-nothing系统。

## Architecture

Snowflake的目标是成为企业级的服务，除了易用性和相互操作性之外，还需要有高可用性。整个Snowflake分为三层：
- 存储层是AWS的S3.
- 虚拟数仓层（virtual warehouse）负责在vm集群上执行query。
- 云服务层，包括了管理VW、query、事务的服务，以及管理元数据的服务。

![](https://fuzhe-pics.oss-cn-beijing.aliyuncs.com/2020-12/snowflake-01.jpg)

### Data Storage

Snowflake选用AWS的原因是：AWS是最成熟的云平台；AWS有着最多的潜在客户。

在S3与自建HDFS的选择中，Snowflake发现S3虽然性能不太稳定，但它的易用性、高可用、强数据可靠性都是很难被替代的。因此Snowflake转而将精力花在了VW层的本地cache和弹性处理倾斜的技术上了。

S3有以下特点：
- 单次访问延时高，CPU消耗大，尤其是使用HTTPS时；
- 文件只能覆盖写，不能追加；
- GET支持只读部分文件；

这些特点严重影响了Snowflake的文件格式和并发控制策略的设计。表被水平分为若干个大的、不可变的文件，每个文件内部使用PAX风格的结构，分为若干个row group，row group内部各列单独存为block。每个文件有一个header，包含了各列的偏移。query只需要读走header和想要的列就可以了。

S3不止用来保存表文件，还会在本地盘用满时保存query算子产生的临时文件。这种设计还增加了一种client间的互动方式，并且简化了query处理，因为不再需要像传统数据库那样在server端维护query的游标了。

元数据则保存在一个可伸缩的事务性的kv store中，属于云服务层的一部分。

### Virtual Warehouses

VW层由若干个EC2集群组成，每个EC2集群称为一个VW，但Snowflake没有直接暴露EC2的信息，而是用抽象的“T-Shirt大小”来代表每个节点的规格，从XS到XXL。这种抽象允许Snowflake独立演进服务和定价，而不会与具体的云服务绑定。

#### Elasticity and Isolation

VW是纯粹的计算层，创建或销毁一个VW对整个DB状态不会有任何影响。用户甚至可以在没有query时停掉所有VW。

一个query只会在一个VW上执行，VW间不共享节点，从而保证了query间的强隔离性（但VW间共享节点是Snowflake的未来目标）。

VW在处理query时会在每个参与的节点上创建一个新worker进程，这个进程会在query结束后就停止。因为表文件都是不可变的，worker进程不会破坏DB状态，挂掉后直接重试即可。目前Snowflake还没有实现部分重试，而是有节点挂掉则整个query重试。

每个用户可能同时有多个VW在运行，每个VW可能同时在处理多个query，这些VW可以看到用户的所有表，而不需要物理拷贝数据。

数据共享意味着用户可以共享/集成自己的所有数据，而计算私有则意味着不同负载和组织之间不会有相互影响，这也是数据集市的意义之一。对于Snowflake的用户来说为不同目的的query准备多个VW是很正常的，偶尔还会按需创建VW来执行批量导入数据之类的任务。

Snowflake的弹性还使得同样的价格下用户可以享受到好很多的性能。比如同样的导数据任务，4个节点的系统可能要15小时，而32个节点的系统只要2小时，两者的价格差不多，但后者的体验好很多。弹性VW就是Snowflake最大的优势和差异点之一。

#### Local Caching and File Stealing

每个节点的本地盘会作为表文件的cache，保存访问过的S3对象，包含header和访问过的列，使用LRU策略淘汰数据。

cache的生命期与节点相同，被这个节点上的所有进程和所有query共享。

为了提升命中率，减少不必要的cache，query优化器会使用一致性哈希，根据表文件名将文件分配给各个节点，后续需要读这些文件的query会被优先发给对应节点。但Snowflake的一致性哈希是惰性的，当有节点变化时数据不会立即洗牌，而是继续依靠LRU淘汰数据。（能这么做是因为它是cache，不涉及正确性）

此外倾斜也是一个重要课题，Snowflake的做法是当一个worker进程A处理完所有文件后，它会从其它进程那里偷一个文件过来，目标进程B如果此时有多个文件待处理，就会同意这次请求，之后进程A会直接从S3上下载这个文件，而不是从进程B那里，避免使B更慢。

#### Execution Engine

Snowflake自己实现了一个全新的列存、向量化、基于push的执行引擎：
- 列存在分析场景的优势是更高效地使用CPU cache、SIMD，有更多机会使用（轻量）压缩。
- Snowflake不会物化中间结果，而是流水线处理，每次批量处理列存格式的数千行数据，节省了I/O，还显著提升了cache效率。
- 上游算子会将它的结果直接推给下游，而不是等着下游来拉（传统的Volcano模型）。这种方式能提升cache效率（从密集循环中移除了控制流逻辑），也允许更高效地处理DAG形状的plan。

同时Snowflake中也没有传统引擎会有的一些开销，如query过程面对的是一组固定的不可变文件，因此不需要事务管理，也不需要buffer pool。大多数query都要处理大量数据，过于限制使用内存没有什么好处，相反Snowflake允许所有主要算子（join/group by/sort）反复将多余数据写到磁盘上。

### Cloud Services

与VW层不同，云服务层是多租户的，负责所有VW的元数据与控制。其中的每个服务都使用多副本来实现高可用与伸缩性。

#### Query Management and Optimization

所有用户发起的query都会先经过云服务层，在这里做完早期处理：解析、对象解析、访问控制、plan优化。

Snowflake的query优化器基于典型的Cascades风格，采用了自上而下、基于cost的优化。